# llm-prompt-leak-framework
Experimental framework for evaluating prompt leakage attacks and defenses in LLMs.
